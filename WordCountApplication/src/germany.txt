Germany, officially Federal Republic of Germany, German Deutschland or Bundesrepublik Deutschland, country of north-central Europe, traversing the continent’s main physical divisions, from the outer ranges of the Alps northward across the varied landscape of the Central German Uplands and then across the North German Plain.

One of Europe’s largest countries, Germany encompasses a wide variety of landscapes: the tall, sheer mountains of the south; the sandy, rolling plains of the north; the forested hills of the urbanized west; and the plains of the agricultural east. At the spiritual heart of the country is the magnificent east-central city of Berlin, which rose phoenixlike from the ashes of World War II and now, after decades of partition, is the capital of a reunified Germany, and the Rhine River, which flows northward from Switzerland and is celebrated in visual art, literature, folklore, and song. Along its banks and those of its principal tributaries—among them the Neckar, Main, Moselle, and Ruhr—stand hundreds of medieval castles, churches, picturesque villages, market towns, and centres of learning and culture, including Heidelberg, the site of one of Europe’s oldest universities (founded in 1386), and Mainz, historically one of Europe’s most important publishing centres. All are centrepieces of Germany’s thriving tourist economy, which brings millions of visitors to the country each year, drawn by its natural beauty, history, culture, and cuisine (including its renowned wines and beers).

The name Germany has long described not a particular place but the loose, fluid polity of Germanic-speaking peoples that held sway over much of western Europe north of the Alps for millennia. Although Germany in that sense is an ancient entity, the German nation in more or less its present form came into being only in the 19th century, when Prussian Prime Minister Otto von Bismarck brought together dozens of German-speaking kingdoms, principalities, free cities, bishoprics, and duchies to form the German Empire in 1871. This so-called Second Reich quickly became Europe’s leading power and acquired colonies in Africa, Asia, and the Pacific. That overseas empire was dismantled following Germany’s defeat in World War I and the abdication of Emperor William II. Economic depression, widespread unemployment, and political strife that verged on civil war followed, leading to the collapse of the progressive Weimar Republic and the rise of the Nazi Party under Adolf Hitler. After gaining power in 1933, Hitler established the Third Reich and soon thereafter embarked on a ruinous crusade to conquer Europe and exterminate Jews, Roma (Gypsies), homosexuals, and others.